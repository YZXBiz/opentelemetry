---
sidebar_position: 8
title: "Chapter 7: Observing Infrastructure"
description: "Cloud providers, Kubernetes, serverless, and async workflows - infrastructure observability with OpenTelemetry"
---

# ðŸ–¥ï¸ Chapter 7: Observing Infrastructure

> **"We build our computer systems the way we build our cities: over time, without a plan, on top of ruins."**
>
> â€” Ellen Ullman

---

## ðŸ“‹ Table of Contents

1. [Introduction](#1-introduction)
2. [What Is Infrastructure Observability?](#2-what-is-infrastructure-observability)
3. [Observing Cloud Providers](#3-observing-cloud-providers)
   - 3.1. [Collecting Cloud Metrics and Logs](#31-collecting-cloud-metrics-and-logs)
   - 3.2. [Push vs. Pull](#32-push-vs-pull)
4. [Observing Platforms](#4-observing-platforms)
   - 4.1. [Kubernetes Platforms](#41-kubernetes-platforms)
   - 4.2. [Serverless Platforms](#42-serverless-platforms)
   - 4.3. [Queues and Async Workflows](#43-queues-and-async-workflows)
5. [Summary](#5-summary)

---

## 1. Introduction

**In plain English:** Your application doesn't run in a vacuumâ€”it runs on servers, containers, and cloud services. Understanding that infrastructure is essential for complete observability.

**In technical terms:** Infrastructure observability captures telemetry from the systems that host and support your applications, including cloud providers, container orchestrators, and serverless platforms.

**Why it matters:** Application telemetry tells you WHAT happened. Infrastructure telemetry tells you WHERE it happened and with what resources. You need both.

---

## 2. What Is Infrastructure Observability?

Infrastructure observability differs from application observability in an important way: **context**.

```
Application Observability              Infrastructure Observability
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

"Request X took 500ms"                "CPU was at 95% when request X
                                       ran on pod Y in node Z"

High correlation with                 Often shared resources
specific requests                     (many requests, same infra)
```

**Two key questions to ask:**

| Question | If Yes | If No |
|----------|--------|-------|
| Can you establish context between infrastructure and application signals? | Worth integrating | Keep separate |
| Does understanding this help achieve business/technical goals? | Worth integrating | May still need monitoring, just not in observability stack |

### The Infrastructure Taxonomy

```
Infrastructure Types
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Providers (source of infrastructure)                            â”‚
â”‚                                                                 â”‚
â”‚ â€¢ Datacenters                                                  â”‚
â”‚ â€¢ Cloud Providers (AWS, GCP, Azure)                            â”‚
â”‚ â€¢ Colocation facilities                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Platforms (abstractions over providers)                         â”‚
â”‚                                                                 â”‚
â”‚ â€¢ Container orchestration (Kubernetes)                         â”‚
â”‚ â€¢ Serverless (Lambda, Cloud Functions)                         â”‚
â”‚ â€¢ CI/CD (Jenkins, GitHub Actions)                              â”‚
â”‚ â€¢ Managed services (RDS, Cloud SQL)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Observing Cloud Providers

### 3.1. Collecting Cloud Metrics and Logs

Cloud providers offer a firehose of telemetry. Your job is to collect what's relevant:

```
The Cloud Telemetry Iceberg
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  What you usually     â”‚  â† Dashboards, alerts
        â”‚  look at              â”‚     (5% of data)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
    ~~~~~~~~~~~~~~~~â”‚~~~~~~~~~~~~~~~~  â† Surface
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  What's available     â”‚  â† API calls, detailed
        â”‚  but rarely used      â”‚     metrics, audit logs
        â”‚                       â”‚     (95% of data)
        â”‚                       â”‚
        â”‚                       â”‚
        â”‚                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Categories of cloud services:**

| Category | Examples | Telemetry Type |
|----------|----------|----------------|
| **Bare infrastructure** | VMs, blob storage, VPCs | System metrics, access logs |
| **Managed services** | RDS, Cloud SQL, ElastiCache | Service metrics, slow query logs |
| **Serverless** | Lambda, Cloud Functions | Invocation metrics, execution logs |

> **âš ï¸ Warning**
>
> Cloud telemetry costs can surprise you! We've seen developers spend $150+ on logging for compute jobs that cost $10. Be purposeful about what you collect.

### Best Practices for Cloud Telemetry

```
Practical Guidelines
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. Use semantic conventions for soft context
   â€¢ Ensure service code and infrastructure use same attribute names
   â€¢ Enables correlation across signals

2. Leverage existing integrations
   â€¢ OpenTelemetry Collector has receivers for most sources
   â€¢ CloudWatch, Azure Monitor, GCP integrations exist

3. Be purposeful with data
   â€¢ Define what you actually need
   â€¢ Set retention policies
   â€¢ Filter early in the pipeline
```

### 3.2. Push vs. Pull

```
Push vs. Pull Metrics Collection
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Push Model (OTLP default)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Service â”‚â”€â”€pushâ”€â–¶â”‚ Collector â”‚â”€â”€â–¶ Backend
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â€¢ Service initiates connection
â€¢ Works through firewalls
â€¢ OTLP uses push


Pull Model (Prometheus style)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”â—€â”€pullâ”€â”€â”‚ Collector â”‚â”€â”€â–¶ Backend
â”‚ Service â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ /metricsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â€¢ Collector initiates connection
â€¢ Service must be reachable
â€¢ Prometheus uses pull
```

**OpenTelemetry Collector can do both:**

```yaml
# Collector config: Pull from Prometheus, Push via OTLP
receivers:
  prometheus:
    config:
      scrape_configs:
        - job_name: 'my-service'
          static_configs:
            - targets: ['service:9090']

exporters:
  otlp:
    endpoint: backend:4317

service:
  pipelines:
    metrics:
      receivers: [prometheus]
      exporters: [otlp]
```

---

## 4. Observing Platforms

### 4.1. Kubernetes Platforms

Kubernetes is complex enough to deserve special attention.

```
Kubernetes Telemetry Sources
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cluster Level                                                    â”‚
â”‚ â€¢ kube-state-metrics (object states)                            â”‚
â”‚ â€¢ API server metrics (request rates, latencies)                 â”‚
â”‚ â€¢ etcd metrics (cluster health)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Node Level                                                       â”‚
â”‚ â€¢ kubelet metrics (pod lifecycle)                               â”‚
â”‚ â€¢ node-exporter (host metrics)                                  â”‚
â”‚ â€¢ Container runtime metrics                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Pod Level                                                        â”‚
â”‚ â€¢ Application telemetry                                         â”‚
â”‚ â€¢ Sidecar container telemetry                                   â”‚
â”‚ â€¢ Resource usage (CPU, memory)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**OpenTelemetry Operator for Kubernetes:**

```
Operator Capabilities
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Collector Management                                             â”‚
â”‚                                                                 â”‚
â”‚ â€¢ DaemonSet: Collector on every node                           â”‚
â”‚ â€¢ Sidecar: Collector in every pod                              â”‚
â”‚ â€¢ Deployment: Collector pool                                    â”‚
â”‚ â€¢ StatefulSet: Stateful collector pool                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Auto-Instrumentation Injection                                  â”‚
â”‚                                                                 â”‚
â”‚ â€¢ Java, Python, Node.js, .NET, Go                              â”‚
â”‚ â€¢ Injects via pod annotation                                   â”‚
â”‚ â€¢ No code changes required                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Target Allocator                                                â”‚
â”‚                                                                 â”‚
â”‚ â€¢ Discovers Prometheus endpoints                               â”‚
â”‚ â€¢ Distributes scrape jobs across collectors                    â”‚
â”‚ â€¢ Enables horizontal scaling                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Example: Auto-instrumentation injection**

```yaml
apiVersion: v1
kind: Pod
metadata:
  annotations:
    # This annotation triggers auto-instrumentation!
    instrumentation.opentelemetry.io/inject-python: "true"
spec:
  containers:
    - name: my-app
      image: my-python-app:latest
```

**Production tips for Kubernetes:**

| Tip | Benefit |
|-----|---------|
| Use sidecar Collectors | Reduces memory pressure on app, cleaner shutdowns |
| Split by signal type | Traces, metrics, logs can scale independently |
| Separate config from code | Easier to adjust without redeploying |

### 4.2. Serverless Platforms

Serverless introduces unique challenges:

```
Serverless Observability Challenges
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Challenge: Ephemeral execution                                   â”‚
â”‚                                                                 â”‚
â”‚ Function starts â†’ Runs â†’ Dies                                   â”‚
â”‚ Must export telemetry before death!                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Challenge: Cold starts                                          â”‚
â”‚                                                                 â”‚
â”‚ First invocation may be slow                                   â”‚
â”‚ Need to track cold vs. warm performance separately             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Challenge: No persistent collector                              â”‚
â”‚                                                                 â”‚
â”‚ Can't run sidecar that outlives function                       â”‚
â”‚ Must push directly or use extension                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Metrics to track for serverless:**

| Metric | Why It Matters |
|--------|---------------|
| **Invocation time** | How long does the function run? |
| **Resource usage** | Memory and compute consumption |
| **Cold start time** | First-invocation latency |
| **Error rate** | Function failures |

**OpenTelemetry Lambda Layer:**

```
Lambda with OTel Layer
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AWS Lambda                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ OpenTelemetry Lambda Layer                                â”‚   â”‚
â”‚ â”‚ â€¢ Auto-instruments common libraries                       â”‚   â”‚
â”‚ â”‚ â€¢ Manages span lifecycle                                  â”‚   â”‚
â”‚ â”‚ â€¢ Flushes on invocation end                              â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ Your Function Code                                        â”‚   â”‚
â”‚ â”‚ â€¢ Runs with tracing enabled                              â”‚   â”‚
â”‚ â”‚ â€¢ No code changes needed for basic telemetry             â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ OTLP
                              â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚    Collector      â”‚
                     â”‚ (dedicated pool)  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.3. Queues and Async Workflows

Event-driven architectures present unique challenges:

```
The Async Observability Problem
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Traditional Request/Response:
User â†’ Service A â†’ Service B â†’ Service C â†’ Response
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ One trace, clear parent-child â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Async/Event-Driven:
User â†’ Service A â†’ Queue â†’ Service B
                       â†“
                    Service C
                       â†“
                    Service D â†’ Queue â†’ Service E

Questions:
â€¢ When does the "transaction" end?
â€¢ How do you trace across queues?
â€¢ What if processing takes hours?
```

**Solution: Span Links**

```
Using Span Links for Async
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Producer (Trace 1)                                              â”‚
â”‚                                                                 â”‚
â”‚ Span: "publish-message"                                         â”‚
â”‚ trace_id: abc123                                                â”‚
â”‚ span_id: 001                                                    â”‚
â”‚                                                                 â”‚
â”‚ Attaches span context to message headers                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ message
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Queue     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Consumer (Trace 2 - NEW trace!)                                 â”‚
â”‚                                                                 â”‚
â”‚ Span: "process-message"                                         â”‚
â”‚ trace_id: xyz789  â† Different trace!                           â”‚
â”‚ span_id: 001                                                    â”‚
â”‚ links: [{trace_id: abc123, span_id: 001}]  â† Link to producer  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why separate traces?**

| Reason | Explanation |
|--------|-------------|
| **Independent failure** | Consumer can retry without affecting producer trace |
| **Time gaps** | Message might sit in queue for hours |
| **Multiple consumers** | One message might be processed by many services |
| **Clear boundaries** | Each "unit of work" is a distinct trace |

> **ðŸ’¡ Insight**
>
> Use span links for async workflows, not parent-child relationships. This lets you correlate work without artificially extending trace duration or creating confusing hierarchies.

---

## 5. Summary

### ðŸŽ“ Key Takeaways

1. **Infrastructure provides context** â€” WHERE things happen, not just WHAT happened

2. **Be purposeful with collection** â€” Cloud telemetry can be expensive; collect what matters

3. **Kubernetes needs the Operator** â€” Manages Collectors and auto-instrumentation

4. **Serverless needs special handling** â€” Ephemeral execution requires careful telemetry flushing

5. **Use span links for async** â€” Don't force parent-child relationships across queues

6. **Start from your goals** â€” Define what you need to observe before collecting everything

### âœ… What's Next

Now you understand how to observe both applications and infrastructure. The next chapter covers designing telemetry pipelinesâ€”how to process, filter, sample, and route all this data efficiently.

---

**Previous:** [Chapter 6: Instrumenting Libraries](./chapter-6-instrumenting-libraries) | **Next:** [Chapter 8: Designing Telemetry Pipelines](./chapter-8-designing-pipelines)
